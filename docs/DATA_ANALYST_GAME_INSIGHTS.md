# DATA_ANALYST_GAME_INSIGHTS.md

> ğŸ“ˆ Documento de Data & Game Insights â€“ alineado con [TASK.MD](./TASK.MD) (fuente de verdad del proyecto)

## 1) DiagnÃ³stico ejecutivo
El estado actual de mediciÃ³n es bajo/no existente: no hay datos de analytics implementados, solo mÃ©tricas bÃ¡sicas de performance en build. 3 riesgos crÃ­ticos: sin datos de usuarios, mÃ©tricas sesgadas por sample limitado, definiciones de sesiÃ³n inconsistentes (no especificadas). 3 insights iniciales: SUPUESTO - D1 retenciÃ³n <50% por falta de engagement post-tutorial, score promedio <5000 por dificultad inicial, session length <2 min por burnout temprano. 3 quick wins de instrumentaciÃ³n/dashboards: integrar Plausible bÃ¡sico para DAU/MAU, evento session_start/end para duraciÃ³n, evento game_start para funnel onboarding.

**Chequeo TASK:** El diagnÃ³stico es correcto. El plan unificado ha elevado **TASK-015 (Agregar Analytics BÃ¡sico)** a **prioridad ğŸ”´ Alta**, convirtiÃ©ndolo en un pilar de la Fase 1. Su alcance se expandirÃ¡ para incluir la lista completa de eventos de la secciÃ³n 8, superando la definiciÃ³n bÃ¡sica inicial.

## 2) Preguntas clave del producto (what we need to know)
Lista de 10 preguntas ordenadas por valor:
1. Â¿DÃ³nde se van los usuarios en onboarding? (funnel drop-off)
2. Â¿QuÃ© alarga la session length promedio?
3. Â¿DÃ³nde mueren mÃ¡s (por nivel/causa)?
4. Â¿QuÃ© items se compran y cuÃ¡ndo?
5. Â¿QuÃ© contenido aburre (replay por nivel)?
6. Â¿CÃ³mo es la distribuciÃ³n de score por segmento?
7. Â¿CuÃ¡l es la curva de dificultad efectiva?
8. Â¿QuÃ© mecÃ¡nicas tienen mÃ¡s engagement (saltos vs colecciÃ³n)?
9. Â¿CÃ³mo varÃ­a el comportamiento mÃ³vil vs desktop?
10. Â¿QuÃ© afecta la retenciÃ³n D7?

Para cada pregunta:
1. KPI principal: Tasa de completitud onboarding. Evento mÃ­nimo: game_start â†’ first_success.
2. KPI principal: Session length mediana. Evento mÃ­nimo: session_start/end.
3. KPI principal: Tasa de Ã©xito por nivel. Evento mÃ­nimo: level_start/end con outcome.
4. KPI principal: Tasa de conversiÃ³n shop. Evento mÃ­nimo: shop_open â†’ item_purchase.
5. KPI principal: Tiempo por nivel. Evento mÃ­nimo: level_start/end con duration.
6. KPI principal: Score p50/p90. Evento mÃ­nimo: game_end con final_score.
7. KPI principal: Intentos antes de pasar nivel. Evento mÃ­nimo: level_restart.
8. KPI principal: Uso por mecÃ¡nica. Evento mÃ­nimo: jump/collect con type.
9. KPI principal: Session length por dispositivo. Evento mÃ­nimo: session_start con device_type.
10. KPI principal: RetenciÃ³n D7. Evento mÃ­nimo: user_id persistente.

## 3) Definiciones de mÃ©tricas (evitar ambigÃ¼edad)
Define (o valida) definiciones canÃ³nicas:
Usuario: ID anÃ³nimo persistente generado con `crypto.randomUUID()` y guardado en `localStorage` (sin PII, sin backend). SesiÃ³n: Periodo continuo de interacciÃ³n, timeout 30 min inactividad (SUPUESTO). Run/Partida: Desde game_start hasta game_over/victory. Score: Suma total de gems + bonuses (incluye multiplicadores por letters).

RetenciÃ³n: D1 y D7 (dÃ­a siguiente al primer play, basado en fecha local). Cohortes (por semana de primera sesiÃ³n).

Session length: Promedio/mediana/p90 (tiempo desde session_start hasta end). "Active play time": Tiempo en status PLAYING (SUPUESTO - estimar con eventos).

Score distribution: Histograma percentiles (p25/p50/p75/p90). Score por segmento (nuevo vs recurrente basado en sessions >1).

## 4) AuditorÃ­a de instrumentaciÃ³n y calidad de datos
Estado actual (con evidencia o SUPUESTO): SUPUESTO - Sin eventos implementados, solo console.log en App.tsx. Lista de eventos existentes: Ninguno. Props por evento: Ninguno. Consistencia: No aplicable.

Problemas tÃ­picos: Eventos faltantes en game_over/victory, ids no Ãºnicos (uuid aleatorios), timestamps sin zona horaria, PII en localStorage si no anonimizado.

Checklist de calidad: Unicidad user_id (SUPUESTO - implementar con crypto.randomUUID). Sesiones infladas (filtrar bots con heurÃ­sticas). Eventos fuera de orden (validar sequence). Campos nulos (required props en schemas).

Tabla obligatoria:
| Evento | PropÃ³sito | Props clave | Estado actual | Riesgo de calidad | Fix propuesto | Prioridad |
|--------|-----------|-------------|---------------|-------------------|---------------|-----------|
| session_start | Inicio sesiÃ³n | user_id, timestamp, device | âœ… Implementado | Sin baseline | âœ… Completado | Alta |
| game_start | Inicio partida | level, lane_count | âœ… Implementado | Funnel roto | âœ… Completado | Alta |
| level_complete | Completitud nivel | level, score, duration | âœ… Implementado | Progreso opaco | âœ… Completado | Media |
| collect_item | ColecciÃ³n | type (gem/letter), value, lane | âœ… Implementado | Engagement invisible | âœ… Completado | Media |
| death | Muerte jugador | reason, level, score | âœ… Implementado | KPIs imposibles | âœ… Completado | Alta |
| shop_open | Apertura tienda | available_items | âœ… Implementado | Sin conversiÃ³n | âœ… Completado | Media |
| item_purchase | Compra item | item_type, cost, remaining_score | âœ… Implementado | Revenue invisible | âœ… Completado | Alta |
| error_captured | Errores | error_type, message (truncated) | âœ… Framework listo | Bugs invisibles | Agregar global handler | Baja |

## 5) KPIs accionables (North Star + soporte)
PropÃ³n 1 North Star KPI: Runs completadas por usuario activo (medida de engagement principal para endless runner).

5 KPIs soporte:
1. RetenciÃ³n D1/D7: Mide stickiness post-onboarding.
2. Session length mediana: Proxy de engagement por sesiÃ³n.
3. Runs por sesiÃ³n: Frecuencia de intentos.
4. Tasa de Ã©xito por nivel: Dificultad balanceada.
5. Score p90: Skill ceiling y motivaciÃ³n.

Para cada KPI:
1. Por quÃ© importa: Mide retenciÃ³n inicial vs viralidad. CÃ³mo se calcula: Usuarios que regresan dÃ­a siguiente/7 dÃ­as. QuÃ© palanca: Mejorar onboarding/tutorial. Riesgo: Sesgos por weekends.
2. Por quÃ© importa: Longitud de engagement por visita. CÃ³mo se calcula: Mediana de duration entre session_start/end. QuÃ© palanca: Contenido variado. Riesgo: Inflado por tabs abiertas.
3. Por quÃ© importa: Persistencia en fallos. CÃ³mo se calcula: Total runs / total sessions. QuÃ© palanca: Balance dificultad. Riesgo: No distingue retries vÃ¡lidos.
4. Por quÃ© importa: Progreso percibido. CÃ³mo se calcula: Niveles completados / niveles intentados. QuÃ© palanca: Pacing de spawns. Riesgo: Levels opcionales.
5. Por quÃ© importa: MotivaciÃ³n de high-skill. CÃ³mo se calcula: Percentil 90 de score distribution. QuÃ© palanca: Rewards por precisiÃ³n. Riesgo: Outliers distorsionan.

## 6) Dashboards propuestos (Plausible / Simple Analytics)
A) Dashboard "Overview"
- DAU/WAU/MAU (mÃ©tricas estÃ¡ndar Plausible)
- RetenciÃ³n D1/D7 (cohortes por fecha primera sesiÃ³n)
- Session length (mediana y p90)
- Runs por usuario y por sesiÃ³n
- Error rate (errores capturados / sessions)

B) Dashboard "Onboarding & Funnel"
- Funnel: landing â†’ session_start â†’ game_start â†’ first_run_complete â†’ level_2_start
- Drop-off por paso (% que pasan al siguiente)
- Tiempo al "aha moment" (primer level complete)

C) Dashboard "Gameplay & Difficulty"
- Muertes por causa (obstacle/alien/missile) y nivel
- Tasa de Ã©xito por nivel
- Score distribution (histograma + percentiles)
- Intentos antes de pasar nivel

D) Dashboard "Segments"
- Nuevo vs recurrente (sessions >1)
- MÃ³vil vs desktop (user agent)
- Browser/OS (Plausible builtin)
- PaÃ­s/idioma (sin PII, solo aggregates)
- Calidad dispositivo (fps_bucket si implementado)

Tabla obligatoria:
| Dashboard | Pregunta | MÃ©tricas | Segmentos | Frecuencia revisiÃ³n | AcciÃ³n tÃ­pica |
|-----------|----------|----------|-----------|---------------------|---------------|
| Overview | Â¿CÃ³mo va el producto? | DAU, retenciÃ³n, session length | Todos | Semanal | Ajustar roadmap |
| Onboarding | Â¿DÃ³nde perdemos usuarios? | Funnel drop-off, tiempo aha | Nuevos | Bi-semanal | Optimizar tutorial |
| Gameplay | Â¿DÃ³nde es difÃ­cil/divertido? | Muertes por nivel, score dist | Activos | Semanal | Balancear dificultad |
| Segments | Â¿QuiÃ©n juega cÃ³mo? | Behavior por device/paÃ­s | Todos | Mensual | Targeting features |

## 7) Informes recurrentes (weekly insights)
Plantilla de informe semanal (1 pÃ¡gina):
Highlights (3): Mejora D1 +0.5%, nuevo feature engagement +20%, score p90 sube 10%. Alertas (2): Drop-off onboarding +5%, error rate >2%. Deep dive (1): AnÃ¡lisis score distribution por nivel. Recomendaciones (3): Ajustar dificultad level 2 (design), agregar evento collect_item (tech), test variante tutorial (ux).

Ejemplos de insights:
- "D1 cae en mÃ³viles por session length corta â†’ medir step onboarding X y optimizar Y"
- "Score p90 sube pero D1 baja â†’ posible dificultad/skill gap, investigar funnel"
- "Runs por sesiÃ³n alta en recurrentes â†’ buen engagement, pero session length baja â†’ optimizar pacing"

Guardrails: CorrelaciÃ³n â‰  causalidad (ej: score alto no implica diversiÃ³n).

## 7.1) ImplementaciÃ³n Actual de Analytics (TASK-015 Completado)

### Arquitectura del Sistema
- **Framework**: Sistema de analytics custom en `src/shared/analytics.ts`
- **Privacidad**: User IDs anÃ³nimos con `crypto.randomUUID()`, sin PII
- **Sesiones**: Timeout automÃ¡tico de 30 minutos de inactividad
- **IntegraciÃ³n**: Eventos instrumentados en Zustand store (`src/features/game/state/store.ts`)
- **InicializaciÃ³n**: Analytics se activa en `src/app/App.tsx` al cargar la aplicaciÃ³n

### Eventos Implementados
Cada evento incluye automÃ¡ticamente: `userId`, `sessionId`, `timestamp`, `deviceInfo`, `url`, `path`

#### Core Events (Prioridad Alta)
- **`session_start`**: Trigger: App initialization
  - Props: `session_type: 'game_session'`
  - PropÃ³sito: Baseline de usuarios activos, session length

- **`game_start`**: Trigger: `startGame()` action
  - Props: `level: number`, `lane_count: number`
  - PropÃ³sito: Funnel onboarding, frecuencia de partidas

- **`level_complete`**: Trigger: `advanceLevel()` action
  - Props: `level: number`, `score: number`, `duration: number`
  - PropÃ³sito: Progreso por nivel, tiempo de completitud

- **`death`**: Trigger: `takeDamage()` cuando vidas = 0
  - Props: `reason: string`, `level: number`, `score: number`
  - PropÃ³sito: Puntos de frustraciÃ³n, balance de dificultad

#### Engagement Events (Prioridad Media)
- **`collect_item`**: Trigger: `collectGem()` y `collectLetter()`
  - Props: `type: 'gem'|'letter'`, `value: number`, `lane: number`
  - PropÃ³sito: Engagement con mecÃ¡nicas de colecciÃ³n

- **`shop_open`**: Trigger: `openShop()` action
  - Props: `available_items: string[]`
  - PropÃ³sito: InterÃ©s en monetizaciÃ³n

- **`item_purchase`**: Trigger: `buyItem()` success
  - Props: `item_type: string`, `cost: number`, `remaining_score: number`
  - PropÃ³sito: ConversiÃ³n de tienda, revenue tracking

### Dashboard Readiness
Con los eventos implementados, los siguientes dashboards pueden ser configurados:

#### Dashboard "Overview" âœ… Ready
- MÃ©tricas: DAU/MAU, session length, runs por usuario
- Eventos requeridos: `session_start`, `game_start`

#### Dashboard "Onboarding & Funnel" âœ… Ready
- Funnel: session_start â†’ game_start â†’ level_complete
- Eventos requeridos: `session_start`, `game_start`, `level_complete`

#### Dashboard "Gameplay & Difficulty" âœ… Ready
- MÃ©tricas: Muertes por nivel, score distribution
- Eventos requeridos: `death`, `level_complete`, `collect_item`

#### Dashboard "Monetization" âœ… Ready
- MÃ©tricas: Shop opens, purchase conversion, revenue por item
- Eventos requeridos: `shop_open`, `item_purchase`

### PrÃ³ximos Pasos
1. **Configurar Plausible/Simple Analytics**: Reemplazar console logs con servicio real
2. **Agregar Error Tracking**: Implementar global error handler para `error_captured`
3. **Performance Metrics**: Agregar `performance_snapshot` con FPS/memory
4. **A/B Testing**: Framework para feature flags con tracking

### ValidaciÃ³n de Calidad
- âœ… User IDs Ãºnicos y persistentes
- âœ… Session management con timeout
- âœ… No PII en eventos
- âœ… Device info no identificable
- âœ… Eventos trigger correctamente en game flow
- âœ… Console logging para desarrollo/debugging

## 8) Plan mÃ­nimo de eventos (si hoy falta instrumentaciÃ³n)
Eventos obligatorios:
- session_start: user_id (anon), timestamp, device_type, referrer
- game_start: level, lane_count, has_upgrades
- run_start: run_id, level, collected_letters
- collect_item: item_type (gem/letter), value, lane, distance_bucket
- level_complete: level, score, duration, attempts
- fail: reason (obstacle/alien/missile), level, position
- game_end: outcome (win/lose), final_score, total_duration
- shop_open: available_items, user_score
- item_purchase: item_type, cost, remaining_score
- performance_snapshot: fps, memory_usage (si disponible)

Para cada evento:
- Props mÃ­nimas: user_id, timestamp, session_id
- Frecuencia esperada: session_start (1/sesiÃ³n), collect_item (10-50/run)
- Riesgos volumen: collect_item alto, sampling 10% para aggregates

## 9. Plan de AcciÃ³n de AnÃ¡lisis de Datos (Alineado con TASK.MD)

El rol del Analista de Datos es transformar el comportamiento del jugador en insights accionables. El plan se alinea con las fases estratÃ©gicas del proyecto, priorizando la obtenciÃ³n de datos antes que el anÃ¡lisis profundo.

### ğŸš€ FASE 1: FUNDACIÃ“N (EstabilizaciÃ³n y MediciÃ³n)
**Objetivo:** Construir la infraestructura de datos desde cero. Pasar de operar "a ciegas" a tener una visiÃ³n clara del comportamiento del usuario.
- **Acciones:**
  - **Definir el Diccionario de Datos (Prioridad Alta):** Formalizar las definiciones de todas las mÃ©tricas (Usuario, SesiÃ³n, RetenciÃ³n) y eventos.
  - **Liderar la ImplementaciÃ³n de Analytics (TASK-015, Prioridad ğŸ”´ Alta):** Instrumentar en el cÃ³digo base el "Plan mÃ­nimo de eventos" (secciÃ³n 8).
  - **Crear Dashboards Fundamentales:** Configurar los dashboards de "Overview" y "Onboarding & Funnel" para monitorear la salud del producto y las primeras fugas de usuarios.
  - **Validar Calidad de Datos:** Realizar chequeos de consistencia para asegurar que los eventos se reciben correctamente y los IDs de usuario son Ãºnicos.

### ğŸ¯ FASE 2: RETENCIÃ“N (DiversiÃ³n y Equidad)
**Objetivo:** Medir el impacto de las mejoras en el core loop y la retenciÃ³n, y proveer insights para el balance.
- **Acciones:**
  - **Analizar el Funnel de RetenciÃ³n:** Usar los datos de la Fase 1 para analizar en profundidad dÃ³nde y por quÃ© los usuarios abandonan el juego despuÃ©s del primer dÃ­a.
  - **Medir Impacto de Features de RetenciÃ³n:** Cuantificar cÃ³mo afectan los **Checkpoints (TASK-017)** y el **Balance de Dificultad (TASK-019)** a la duraciÃ³n de la sesiÃ³n y la tasa de finalizaciÃ³n de niveles.
  - **Crear Dashboard de Gameplay:** Desarrollar el dashboard "Gameplay & Difficulty" para visualizar las muertes por nivel, la distribuciÃ³n de scores y los puntos de fricciÃ³n.
  - **Soportar A/B Testing:** Preparar la infraestructura de anÃ¡lisis para medir los resultados de los A/B testing clientâ€‘side (feature flags locales) que segÃºn decisiones de producto se decidan ejecutar.

### ğŸŒŸ FASE 3: EXPANSIÃ“N (Profundidad y Contenido)
**Objetivo:** Analizar el engagement con el nuevo contenido y encontrar patrones en segmentos de jugadores a largo plazo.
- **Acciones:**
  - **Medir Engagement de Nuevas Features:** Analizar el uso del **Sistema de Combate (TASK-021)** y otras features de expansiÃ³n.
  - **Desarrollar SegmentaciÃ³n Avanzada:** Crear el dashboard de "Segments" para encontrar diferencias de comportamiento entre jugadores nuevos vs. recurrentes, mÃ³vil vs. desktop, etc.
  - **Generar Informes de Insights:** Comenzar a generar los informes semanales con recomendaciones accionables para decisiones de producto y diseÃ±o.

> ğŸ“˜ MÃ¡s contexto general: [README.md](../README.md)

---
ğŸ”— Este documento estÃ¡ alineado con la fuente de verdad del proyecto ([TASK.MD](./TASK.MD)).
Ãšltima sincronizaciÃ³n automÃ¡tica: 2025-12-17
